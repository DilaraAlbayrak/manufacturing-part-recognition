[Pytorch implementation](https://github.com/RBirkeland/MVCNN-PyTorch) of a novel multi-view 3D shape recognition paper [[1]](#1) was mainly adopted and widely used in this project. 

# Manufacturing part recognition by training 2D views

This study is a 3D object recognition by 2D images project for manufacturing parts along an assembly line. We adopted the "Multi-View Convolutional Neural Networks for 3D Shape Recognition" (MVCNN) [[1]](#1) paper and add new approaches for the model to recognize 101 parts (classes). The paper uses 12 (and more) rendered views whereas it is not practical to get several views, i.e., 15-20, for inference in a real-world setting. Thus, we kept the number of views small (3 views). Initially, the model was given fewer classes (first 10, then 20, then 50). However, the model performance dropped as the number of classes increased. Then, we chose to apply two-stage architecture, where we grouped classes randomly, (let's say classes 1, 6, 59, 95, 30 are labeled as group 1; classes 12, 77, 64, 3, 88 are labeled as group 2 and so on). The goal of the first stage is to label the groups of classes correctly whereas, the second stage recognizes the correct class label among each randomly assigned group.

![model architecture](https://user-images.githubusercontent.com/7215154/181904515-1cab3b5f-1b85-4456-82c3-7fdb41319bfa.svg)
<br />
<br />
<br />
Unity game engine was used to generate the train set, we obtained renderings of 3D models from three views. 3D models were .stl format, initially, we convert them to .obj so that unity can import the models. We added random scaling to the original size between [0.9, 1.1], and applied axis-independent random translate factors translate with a range of [-1/6w, 1/6w], where w is the width of the simulation environment and random rotation to give the objects tilt movement. This randomization enhanced the number of samples in the dataset. After we generate the renderings, we applied motion blur to 1/3 of the samples.

https://user-images.githubusercontent.com/7215154/181916282-794f3a1c-50fd-491e-97cd-38d16e4f03ac.mp4

<br />
<br />  
The purpose of the recognition task is to make the finalized model recognize 3D objects in the real world (the assembly line) while it was trained with the synthetic 2D images rendered by Unity. For that purpose, we constructed a physical cabin with three cameras in front of a white background to use it as an assembly-line setting. Our main goal was to increase the model performance for the inference task of the object views captured in that cabin.

![cabin](https://user-images.githubusercontent.com/7215154/181916801-7441580c-9b50-4e26-809f-e3638272d430.svg)
<br />
<br />
<br />
After some training phase and getting some results with some regularization factors, we saw that the dataset needed to be augmented to deal with overfitting. Our data augmentation approach was based on Domain Randomization [[2]](#2). It suggests extending the variety of the simulated samples so that the chances for the simulation environment to reach the real-world increases.

![https://lilianweng.github.io/posts/2019-05-05-domain-randomization/](https://lilianweng.github.io/posts/2019-05-05-domain-randomization/sim2real-transfer.png)
*[The figure was taken from Lilian Weng's post titled "Domain Randomization for Sim2Real Transfer"](https://lilianweng.github.io/posts/2019-05-05-domain-randomization/)*
<br />
<br />
<br />
With this in mind, we added artifacts and noise to the simulation environment generated by Unity, such that:
-	Background texture: 20 different textures were applied randomly to the background. These textures could be plain or have noise or patterns.
-	Illumination: There were 4 lights in the simulation setting. They could be enabled or disabled, and their intensities were randomly changed.


### References
<a id="1">[1]</a> 
Su, Hang, et al. "Multi-view convolutional neural networks for 3d shape recognition." Proceedings of the IEEE international conference on computer vision. 2015.

<a id="2">[2]</a> 
Tobin, Josh, et al. "Domain randomization for transferring deep neural networks from simulation to the real world." 2017 IEEE/RSJ international conference on intelligent robots and systems (IROS). IEEE, 2017.
